{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import asyncio\n",
    "import websockets\n",
    "import json as json\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-b5c22b5b679a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-b5c22b5b679a>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    await websocket.send(\"{ \\\"op\\\": \\\"advertise_service\\\",              \\\"type\\\": \\\"roboy_communication_cognition/GenerateAnswer\\\",              \\\"service\\\": \\\"/roboy/cognition/generative_nlp/answer\\\"            }\")\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Service /roboy/cognition/generative_nlp/answer is ready\")\n",
    "\n",
    "# wait for the service request, generate the answer, and send it back\n",
    "# advertise the service\n",
    "await websocket.send(\"{ \\\"op\\\": \\\"advertise_service\\\",\\\n",
    "              \\\"type\\\": \\\"roboy_communication_cognition/GenerateAnswer\\\",\\\n",
    "              \\\"service\\\": \\\"/roboy/cognition/generative_nlp/answer\\\"\\\n",
    "            }\")\n",
    "\n",
    "    i = 1 # counter for the service request IDs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model integration\n",
    "from parlai.core.build_data import download_models\n",
    "from parlai.core.params import ParlaiParser\n",
    "#from parlai.scripts.interactive import interactive\n",
    "from projects.personachat.persona_seq2seq import PersonachatSeqseqAgentSplit\n",
    "from parlai.core.agents import create_agent\n",
    "from parlai.core.worlds import create_task\n",
    "from parlai.agents.local_human.local_human import LocalHumanAgent\n",
    "import pdb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive(opt):\n",
    "    if isinstance(opt, ParlaiParser):\n",
    "        print('[ Deprecated Warning: interactive should be passed opt not Parser ]')\n",
    "        opt = opt.parse_args()\n",
    "    opt['task'] = 'parlai.agents.local_human.local_human:LocalHumanAgent'\n",
    "\n",
    "    # Create model and assign it to the specified task\n",
    "    agent = create_agent(opt, requireModelExists=True)\n",
    "    world = create_task(opt, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-t TASK] [--download-path DOWNLOAD_PATH]\n",
      "                             [-dt {train,train:stream,train:ordered,train:ordered:stream,train:stream:ordered,train:evalmode,train:evalmode:stream,train:evalmode:ordered,train:evalmode:ordered:stream,train:evalmode:stream:ordered,valid,valid:stream,test,test:stream}]\n",
      "                             [-im IMAGE_MODE] [-nt NUMTHREADS]\n",
      "                             [--hide-labels HIDE_LABELS] [-bs BATCHSIZE]\n",
      "                             [-bsrt BATCH_SORT] [-clen CONTEXT_LENGTH]\n",
      "                             [-incl INCLUDE_LABELS] [-dp DATAPATH] [-m MODEL]\n",
      "                             [-mf MODEL_FILE] [--dict-class DICT_CLASS]\n",
      "                             [-d DISPLAY_EXAMPLES] [--image-size IMAGE_SIZE]\n",
      "                             [--image-cropsize IMAGE_CROPSIZE]\n",
      "                             [--dict-file DICT_FILE]\n",
      "                             [--dict-initpath DICT_INITPATH]\n",
      "                             [--dict-language DICT_LANGUAGE]\n",
      "                             [--dict-max-ngram-size DICT_MAX_NGRAM_SIZE]\n",
      "                             [--dict-minfreq DICT_MINFREQ]\n",
      "                             [--dict-maxtokens DICT_MAXTOKENS]\n",
      "                             [--dict-nulltoken DICT_NULLTOKEN]\n",
      "                             [--dict-starttoken DICT_STARTTOKEN]\n",
      "                             [--dict-endtoken DICT_ENDTOKEN]\n",
      "                             [--dict-unktoken DICT_UNKTOKEN]\n",
      "                             [-tok DICT_TOKENIZER] [--dict-lower DICT_LOWER]\n",
      "                             [-hs HIDDENSIZE] [-emb EMBEDDINGSIZE]\n",
      "                             [-nl NUMLAYERS] [-lr LEARNINGRATE] [-dr DROPOUT]\n",
      "                             [-bi] [-att ATTENTION] [--no-cuda] [--gpu GPU]\n",
      "                             [-rc RANK_CANDIDATES] [-tr TRUNCATE]\n",
      "                             [-enc {rnn,gru,lstm}]\n",
      "                             [-dec {same,shared,rnn,gru,lstm}]\n",
      "                             [-opt {adadelta,adagrad,adam,adamax,asgd,lbfgs,rmsprop,rprop,sgd}]\n",
      "                             [--personachat_useprevdialog]\n",
      "                             [--personachat_printattn]\n",
      "                             [--personachat_attnsentlevel]\n",
      "                             [--personachat_sharelt]\n",
      "                             [--personachat_reweight PERSONACHAT_REWEIGHT]\n",
      "                             [--personachat_guidesoftmax]\n",
      "                             [--personachat_newsetting PERSONACHAT_NEWSETTING]\n",
      "                             [--personachat_interact] [--personachat_pdmn]\n",
      "                             [--personachat_tfidfperp]\n",
      "                             [--personachat_learnreweight]\n",
      "                             [--personachat_embshareonly_pm_dec]\n",
      "                             [--personachat_s2sinit]\n",
      "                             [--interactive-mode INTERACTIVE_MODE]\n",
      "                             [--use-persona {self,none,other,both}]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/christoph/Library/Jupyter/runtime/kernel-24c39ad2-5b1f-4f54-b2b1-fb12d53061f8.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christoph/Documents/Roboy/FacebookResearch/venvFB/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = ParlaiParser(add_model_args=True)\n",
    "parser.add_argument('-d', '--display-examples', type='bool', default=False)\n",
    "parser.set_defaults(\n",
    "    model='projects.personachat.persona_seq2seq:PersonachatSeqseqAgentSplit',\n",
    "    model_file='models:convai2/profilememory/profilememory_convai2_model',\n",
    "    dict_file='models:convai2/profilememory/profilememory_convai2.dict',\n",
    "    interactive_mode=True,\n",
    ")\n",
    "\n",
    "opt = parser.parse_args()\n",
    "opt['model_type'] = 'profilememory' # for builder\n",
    "# build profile memory models\n",
    "fnames = ['profilememory_convai2_model',\n",
    "          'profilememory_convai2.dict']\n",
    "download_models(opt, fnames, 'convai2', use_model_type=True)\n",
    "interactive(opt)\n",
    "\n",
    "#from parlai.core.params import ParlaiParser\n",
    "\n",
    "\n",
    "#def setup_args(parser=None):\n",
    "#    if parser is None:\n",
    "#        parser = ParlaiParser(True, True)\n",
    "#    parser.add_argument('-d', '--display-examples', type='bool', default=False)\n",
    "#    parser.add_argument('--display-prettify', type='bool', default=False,\n",
    "#                        help='Set to use a prettytable when displaying '\n",
    "#                             'examples with text candidates')\n",
    "#    parser.add_argument('--display-ignore-fields',type=str,\n",
    "#                        default='label_candidates,text_candidates',\n",
    "#                        help='Do not display these fields')\n",
    "#    LocalHumanAgent.add_cmdline_args(parser)\n",
    "#    return parser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Show some example dialogs:\n",
    "#    while True:\n",
    "#        world.parley()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer = world.parley()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Service /roboy/cognition/generative_nlp/answer is ready\")\n",
    "\n",
    "    # wait for the service request, generate the answer, and send it back\n",
    "while True:\n",
    "    try:\n",
    "        request = await websocket.recv()\n",
    "\n",
    "        sentence = json.loads(request)[\"args\"][\"text_input\"]\n",
    "        #print(sentence)\n",
    "        #answer = cb.singlePredict(sentence,[])\n",
    "        answer = world.parley"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
